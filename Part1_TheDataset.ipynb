{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles1_df = pd.read_csv('articles1_common.csv')\n",
    "articles2_df = pd.read_csv('articles2_aljazeera.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_list1 = ['targe']\n",
    "columns_to_drop_list2 = ['guid', 'published', 'title', 'description', 'link', 'image', 'ref', 'tags']\n",
    "\n",
    "articles1_df = articles1_df.drop(columns_to_drop_list1, axis=1)\n",
    "articles2_df = articles2_df.drop(columns_to_drop_list2, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111728\n",
      "5870\n",
      "Number of documents in total: 117598\n"
     ]
    }
   ],
   "source": [
    "print(len(articles1_df))\n",
    "print(len(articles2_df))\n",
    "print(f'Number of documents in total: {len(articles1_df) + len(articles2_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_extra_newlines(data):\n",
    "    data = re.sub(r'\\n\\s*\\n', '\\n', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_long_letters(data):\n",
    "    data = re.sub(r'ـ\\s*ـ', '', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_space_between_special_characters(data):\n",
    "    data = re.sub(r'[”]', ' ” ', data)\n",
    "    data = re.sub(r'[\"]', ' \" ', data)\n",
    "    data = re.sub(r'[\"\"]', ' \" ', data)\n",
    "    data = re.sub(r'[،]', ' ، ', data)\n",
    "    data = re.sub(r'[.]', ' . ', data)\n",
    "    data = re.sub(r'[:]', ' : ', data)\n",
    "    data = re.sub(r'[؛]', ' ؛ ', data)\n",
    "    data = re.sub(r'»', ' » ', data)\n",
    "    data = re.sub(r'«', ' « ', data)\n",
    "    data = re.sub(\"[?]\", \" ? \", data)\n",
    "    data = re.sub(\"[!]\", \" ! \", data)\n",
    "    data = re.sub(\"[%]\", \" % \", data)\n",
    "    data = re.sub(\"[*]\", \" * \", data)\n",
    "    data = re.sub(\"[/]\", \" / \", data)\n",
    "    data = re.sub(\"–\", \" – \", data)\n",
    "    data = re.sub(\"<\", \" < \", data)\n",
    "    data = re.sub(\">\", \" > \", data)\n",
    "    data = re.sub(\"-\", \" - \", data)\n",
    "    data = re.sub(\"[(]\", \" ( \", data)\n",
    "    data = re.sub(\"[)]\", \" ) \", data)\n",
    "    data = re.sub(\"[[]\", \" [ \", data)\n",
    "    data = re.sub(\"[]]\", \" ] \", data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_arabic_digits(data):\n",
    "    data = re.sub('0', '٠', data)\n",
    "    data = re.sub('1', '١', data)\n",
    "    data = re.sub('2', '٢', data)\n",
    "    data = re.sub('3', '٣', data)\n",
    "    data = re.sub('4', '٤', data)\n",
    "    data = re.sub('5', '٥', data)\n",
    "    data = re.sub('6', '٦', data)\n",
    "    data = re.sub('7', '٧', data)\n",
    "    data = re.sub('8', '٨', data)\n",
    "    data = re.sub('9', '٩', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_duplicate_quotes(data):\n",
    "    data = re.sub(r'\"+', '\"', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def replace_extra_whitespaces_into_one(data):\n",
    "    data = re.sub(' +', ' ', data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def apply_all(data):\n",
    "    data = remove_extra_newlines(data)\n",
    "    data = remove_long_letters(data)\n",
    "    data = create_space_between_special_characters(data)\n",
    "    data = to_arabic_digits(data)\n",
    "    data = replace_extra_whitespaces_into_one(data)\n",
    "    data = remove_duplicate_quotes(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(df, text_column_name='text'):\n",
    "    df[text_column_name] = df[text_column_name].apply(lambda x: apply_all(x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data and getting rid of unneccessary tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badea\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:32: FutureWarning: Possible nested set at position 1\n"
     ]
    }
   ],
   "source": [
    "for i, row in articles1_df.iterrows():\n",
    "    if type(row['text']) != str:\n",
    "        row['text'] = str(row['text'])\n",
    "        articles1_df.drop(labels=i, axis=0, inplace=True)\n",
    "    row['text'] = apply_all(row['text'])\n",
    "\n",
    "for i, row in articles2_df.iterrows():\n",
    "    if type(row['text']) != str:\n",
    "        row['text'] = str(row['text'])\n",
    "        articles2_df.drop(labels=i, axis=0, inplace=True)\n",
    "    row['text'] = apply_all(row['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles1_df.to_csv('articles1.csv')\n",
    "articles2_df.to_csv('articles2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65cb2dea25fc8bfd6eddbece3918c0c29f3be73d0a0d3d6538232ed13a9a2282"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
